{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traceroute Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook containing preliminary exploration of cybersecuirty related data pulled from both benign and malicious sources\n",
    "# with the goal of identifying suspicious websites using various machine learning models.\n",
    "\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pprint\n",
    "import operator\n",
    "import os\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "from ipwhois import IPWhois\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from bisect import bisect_left\n",
    "import socket, struct\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enumerate filenames of all json documents for stragithforward iteration\n",
    "\n",
    "date_path = '/data/data/2019-06-03/'\n",
    "enrichment=date_path+'enrichment/'\n",
    "ingest=date_path+'ingest/'\n",
    "stream='traceroute'\n",
    "\n",
    "# Index: list of all json names in the folder of a particular date\n",
    "index=dict.fromkeys(os.listdir(enrichment))\n",
    "for x in index:\n",
    "    index[x]=os.listdir(enrichment+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of times each route crosses a certian IP\n",
    "frequency_counts_benign=defaultdict(int)\n",
    "frequency_counts_malicious=defaultdict(int)\n",
    "\n",
    "#Lists to keep track of various features throughout iteration\n",
    "frames=[] #Holds a complete dataframe for each json file \n",
    "populated=True #Determines whether a json was empty\n",
    "totalRoutes=[] #Contains all routes \n",
    "totalBRoutes=[] # ^^ for \"benign\" routes\n",
    "totalMRoutes=[] # ^^ for \"malicious\" routes\n",
    "totalDest=set() #Tracks all the destination nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=json.load(open('subnetDirectory.json'))\n",
    "beta=json.load(open('subnetDirectory1.json'))\n",
    "gamma=json.load(open('subnetDirectory2.json'))\n",
    "delta=json.load(open('subnetDirectory3.json'))\n",
    "consolidated={**alpha,**beta,**gamma,**delta}\n",
    "del alpha\n",
    "del beta\n",
    "del gamma\n",
    "del delta\n",
    "\n",
    "#Manually insert certain IPs\n",
    "consolidated['58.120.0.0']=13\n",
    "consolidated['203.234.128.0']=16\n",
    "consolidated['0.0.0.0']=32\n",
    "consolidated['211.206.0.0']=14\n",
    "consolidated['1.208.0.0 ']=12\n",
    "consolidated['103.70.240.0']=22\n",
    "consolidated['183.96.0.0']=14\n",
    "consolidated['112.160.0.0']=11\n",
    "consolidated['113.216.0.0']=15\n",
    "consolidated['220.70.0.0']=15\n",
    "consolidated['218.152.0.0']=14\n",
    "consolidated['111.118.0.0']=17\n",
    "consolidated['39.112.0.0']=12\n",
    "consolidated['52.88.0.0']=13\n",
    "consolidated['99.78.128.0']=17\n",
    "consolidated['99.79.0.0']=16\n",
    "consolidated['99.80.0.0']=15\n",
    "consolidated['99.82.0.0']=17\n",
    "consolidated['99.82.128.0']=18\n",
    "consolidated['23.192.0.0']=11\n",
    "consolidated['104.16.0.0']=12\n",
    "consolidated['152.176.0.0']=12\n",
    "consolidated['152.192.0.0']=13\n",
    "consolidated['183.111.0.0']=16\n",
    "consolidated['110.76.140.0']=22\n",
    "consolidated['203.246.160.0']=21\n",
    "consolidated['1.208.0.0']=12\n",
    "consolidated['125.128.0.0']=11\n",
    "consolidated['121.128.0.0']=11\n",
    "\n",
    "jsonWrite = json.dumps(con)\n",
    "f = open(\"subnetDirectory.json\",\"w\")\n",
    "f.write(jsonWrite)\n",
    "f.close()\n",
    "\n",
    "\n",
    "k=list(consolidated.keys())\n",
    "k=sorted(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCIDR(alpha):\n",
    "    ip=alpha[:alpha.find('/')]\n",
    "    mask=alpha[alpha.find('/')+1:]\n",
    "    return (ip, int(mask))\n",
    "    \n",
    "def dottedQuadToNum(ip):\n",
    "    \"convert decimal dotted quad string to long integer\"\n",
    "    return struct.unpack('!L',socket.inet_aton(ip))[0]\n",
    "\n",
    "def numToDottedQuad(n):\n",
    "    \"convert long int to dotted quad string\"\n",
    "    return socket.inet_ntoa(struct.pack('!L',n))\n",
    "      \n",
    "def makeMask(n):\n",
    "    \"return a mask of n bits as a long integer\"\n",
    "    return (1 << 32-n)-1\n",
    "\n",
    "def ipToNetAndMask(ip):\n",
    "    \"returns tuple (network, host) dotted-quad addresses given IP and mask size\"\n",
    "    if (len(ip) > 18):\n",
    "        ip=ip[:ip.find(',')]\n",
    "    network,mask = parseCIDR(ip)\n",
    "    n = dottedQuadToNum(network)\n",
    "    m = makeMask(mask)\n",
    "\n",
    "    host = n & m\n",
    "    net = n - host\n",
    "\n",
    "    return numToDottedQuad(net), mask\n",
    "\n",
    "def toNet(network,maskbits):\n",
    "    \"returns tuple (network, host) dotted-quad addresses given IP and mask size\"\n",
    "    n = dottedQuadToNum(network)\n",
    "    m = makeMask(maskbits)\n",
    "\n",
    "    host = n & m\n",
    "    net = n - host\n",
    "\n",
    "    return numToDottedQuad(net)\n",
    "\n",
    "registered=0\n",
    "allFailures=[]\n",
    "def oneHotEncode(hops):\n",
    "    global allFailures\n",
    "    global registered\n",
    "    ret=np.zeros(len(k)+1)\n",
    "    for point in hops:\n",
    "        if (point != '***'):\n",
    "            \n",
    "            \n",
    "            for i in range (32,0,-1):\n",
    "                ref=toNet(point,i)\n",
    "                if (consolidated.get(ref,False)):\n",
    "                    if (consolidated[ref] == i):\n",
    "                        ret[consolidated[ref]]=1\n",
    "                        break\n",
    "            else:\n",
    "                allFailures.append(point)\n",
    "            #pos=bisect_left(k,point)\n",
    "\n",
    "            #if (pos > 0):\n",
    "            #    pos-=1\n",
    "\n",
    "            #if (toNet(point,consolidated[k[pos]]) != k[pos]):\n",
    "            #    allFailures.append(point)\n",
    "            #else:\n",
    "            #    ret[pos]=1\n",
    "            #    registered+=1\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For each json in the \"stream\" folder for a particular date...\n",
    "for w in index[stream]:\n",
    "    temp_json=json.load(open(enrichment+stream+'/'+w))\n",
    "    if type(temp_json[\"data\"]) == list:\n",
    "        frames.append(pd.DataFrame(temp_json[\"data\"]))  \n",
    "    \n",
    "    #For each element in the data list from the traceroute json...\n",
    "    all_trace=[]\n",
    "    all_ping=[]\n",
    "    all_benign=[]\n",
    "    all_dest=[]\n",
    "    all_route_lengths=[]\n",
    "    all_avg_ping=[]\n",
    "    all_timeouts=[]\n",
    "    all_weighted_ping=[]\n",
    "    expanded_route=[]\n",
    "    \n",
    "    for route in temp_json[\"data\"]:\n",
    "        \n",
    "        #Error handling\n",
    "        if type(route) is str:\n",
    "            populated=False\n",
    "            break\n",
    "            \n",
    "        # Determine benign or malicious feature set\n",
    "        if (len(w)<10):\n",
    "            all_benign.append(True)\n",
    "        else:\n",
    "            all_benign.append(False)\n",
    "            \n",
    "        #Parse the string of traceroute data\n",
    "        split=route[\"traceroute\"].splitlines()\n",
    "        all_route_lengths.append(len(split)-1)\n",
    "        hops=[]\n",
    "        pings=[]\n",
    "        \n",
    "        #For each line in the traceroute for a given indicator\n",
    "        count=0\n",
    "        timeouts=0\n",
    "        for x in split:\n",
    "            regIP=re.findall(\"([(]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[)])\",x)\n",
    "            regPing=re.findall(\"\\s\\d+[.]\\d{3}\\s\",x)\n",
    "            pings.append(regPing)\n",
    "            for ip in regIP:\n",
    "                if (count ==0):\n",
    "                    all_dest.append(ip)\n",
    "                    count=1\n",
    "                ip=ip[1:-1]\n",
    "                totalDest.add(ip)\n",
    "                hops.append(ip)\n",
    "                if (len(w)<10): \n",
    "                    frequency_counts_benign[ip]+=1\n",
    "                    break\n",
    "                else:\n",
    "                    frequency_counts_malicious[ip]+=1\n",
    "                    break\n",
    "            if (count == 0):\n",
    "                all_dest.append(\"***\")\n",
    "                count=1\n",
    "                \n",
    "            if (len(regIP) == 0):\n",
    "                hops.append(\"***\")\n",
    "                timeouts=timeouts+1\n",
    "                \n",
    "        #Append each IP node from this indicator to a list of lists containing all routes for all jsons on this day\n",
    "        all_trace.append(hops[1:])\n",
    "        totalRoutes.append(hops)\n",
    "        if (len(w)<10):\n",
    "            totalBRoutes.append(hops)\n",
    "        else:\n",
    "            totalMRoutes.append(hops)\n",
    "            \n",
    "            \n",
    "        # One-hot encoding    \n",
    "        expanded_route.append(pd.DataFrame([oneHotEncode(hops)]))\n",
    "        \n",
    "        \n",
    "        all_ping.append(pings[1:])\n",
    "        all_timeouts.append(timeouts)\n",
    "        overallPing=0\n",
    "        weighted_ping=0\n",
    "        idx=1\n",
    "        for trio in pings:\n",
    "            if (len(trio) != 0):\n",
    "                overallPing=overallPing+float(min(trio))\n",
    "                weighted_ping=weighted_ping+float(min(trio))*idx*idx\n",
    "                idx+=1\n",
    "                \n",
    "            \n",
    "        all_avg_ping.append(overallPing/(all_route_lengths[len(all_route_lengths)-1]-timeouts))\n",
    "        all_weighted_ping.append(weighted_ping/(all_route_lengths[len(all_route_lengths)-1]-timeouts))\n",
    "        \n",
    "    #print(frames[len(frames)-1].shape)\n",
    "    #print(len(all_trace))\n",
    "    #print(w)\n",
    "    \n",
    "    if (populated):\n",
    "        frames[len(frames)-1].insert(2,\"Route\",all_trace)\n",
    "        frames[len(frames)-1].insert(3,\"Ping\",all_ping)\n",
    "        frames[len(frames)-1].insert(1,\"Benign\",all_benign)\n",
    "        frames[len(frames)-1].insert(2,\"Dest\",all_dest)\n",
    "        frames[len(frames)-1].insert(2,\"NumHops\",all_route_lengths)\n",
    "        frames[len(frames)-1].insert(2,\"AveragePing\",all_avg_ping)\n",
    "        frames[len(frames)-1].insert(2,\"Timeouts\",all_timeouts)\n",
    "        frames[len(frames)-1]=pd.concat([frames[len(frames)-1], pd.concat(expanded_route).reset_index()], axis=1)\n",
    "        #frames[len(frames)-1]=pd.concat([frames[len(frames)-1],pd.concat(expanded_route)],axis=1,join_axes=[frames[len(frames)-1].index])\n",
    "        #frames[len(frames)-1]\n",
    "    else:\n",
    "        populated=True\n",
    "        frames.pop()\n",
    "\n",
    "del all_trace\n",
    "del all_ping\n",
    "del all_benign\n",
    "del all_dest\n",
    "del all_route_lengths\n",
    "del all_avg_ping\n",
    "del all_timeouts\n",
    "del all_weighted_ping\n",
    "del pings\n",
    "del hops\n",
    "del expanded_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(allFailures))\n",
    "#pprint.pprint(allFailures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upset={}\n",
    "iterCount=0\n",
    "for test in allFailures:\n",
    "    iterCount+=1\n",
    "    if (iterCount % 250 == 0):\n",
    "        print (iterCount/25000)\n",
    "\n",
    "    try:\n",
    "        tmp=IPWhois(test,allow_permutations=True).lookup_rdap()['network']['cidr']\n",
    "        if (tmp.find(',')):\n",
    "            for annoy in tmp.split(','):\n",
    "                annoy=annoy.strip()\n",
    "                newSubnet,newMask=ipToNetAndMask(annoy)\n",
    "                upset[newSubnet]=newMask\n",
    "        else:\n",
    "            print(\"diff:\",test)\n",
    "            \n",
    "    except:\n",
    "        print(\"Error:\", test)\n",
    "        \n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spare regex expressions \n",
    "\n",
    "\n",
    "#print(time.time()-t1)           \n",
    "\n",
    "#regDNS=re.findall(\"(\\s[\\w\\-._~:\\/\\?\\#\\[\\]\\@\\!\\$\\&\\'\\(\\)\\*\\+\\,\\;\\=]+\\s)([(]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[)])\",x)\n",
    "#reg1=re.findall(\"([(]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[)])(\\s+\\d+[.]\\d{3}\\sms)+\",x)\n",
    "#reg1=re.findall(\"[(]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[)]\\s+\\d+[.]\\d{3}\\s\",x)\n",
    "\n",
    "#q=-1\n",
    "#for x in s:\n",
    "    #q=q+1\n",
    "    #Parse ip adresses and latency\n",
    "    #print(q, re.findall(\"[(]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[.]\\d{1,3}[)]\",x), re.findall(\"\\s\\d+[.]\\d{3}\\s\",x))\n",
    "    #print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(frames)\n",
    "del frames\n",
    "df=df.fillna(\"X\")\n",
    "df.drop(columns=['traceroute','index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification Models\n",
    "\n",
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "X=df[['Timeouts','AveragePing','NumHops','success']]\n",
    "Y=df['Benign']\n",
    "#clf=sklearn.tree.DecisionTreeClassifier()\n",
    "#clf = clf.fit(X.loc[0:3000,:],Y.loc[0:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(Y, clf.predict(X))))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(Y, clf.predict(X),labels=[False,True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(Y.loc[3001:6000], clf.predict(X.loc[3001:6000,:]))))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(Y.loc[3001:6000], clf.predict(X.loc[3001:6000,:]),labels=[False,True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDest=sorted(totalDest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom One Hot Encoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(totalDest)\n",
    "from bisect import bisect_left\n",
    "sample_onehot=[0]*len(totalDest)\n",
    "t0=time.time()\n",
    "for x in hops:\n",
    "    sample_onehot[bisect_left(totalDest,x)]=1\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Sqare Analysis of IP Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srt_benign=pd.DataFrame(sorted(frequency_counts_benign.items(), key=operator.itemgetter(1), reverse=True), columns=[\"BenignIP\",\"BenignFreq\"])\n",
    "srt_malicious=pd.DataFrame(sorted(frequency_counts_malicious.items(), key=operator.itemgetter(1), reverse=True),columns=[\"MalIP\",\"MalFreq\"])\n",
    "srt=pd.concat([srt_benign,srt_malicious], axis=1)\n",
    "srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freqB=[]\n",
    "freqM=[]\n",
    "for x in frequency_counts_benign.keys():\n",
    "    if frequency_counts_malicious.get(x) != None:\n",
    "        freqB.append(frequency_counts_benign.get(x))\n",
    "        freqM.append(frequency_counts_malicious.get(x)/5.4)\n",
    "\n",
    "print(pd.Series(freqB).sum(),pd.Series(freqM).sum())\n",
    "chisquare(freqM, f_exp=freqB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(totalBRoutes), len(totalMRoutes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Graph of IP Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "\n",
    "#Add nodes to graph\n",
    "for x in totalRoutes:\n",
    "    x=list(filter(lambda a:a!=\"***\",x))\n",
    "    G.add_nodes_from(x)\n",
    "    #if (df.iloc[c][2]):\n",
    "        #colorCode=colorCode+['blue']*(len(x)-1)\n",
    "    #else:\n",
    "         #colorCode=colorCode+['red']*(len(x)-1)\n",
    "        \n",
    "    #Add adges and connect last node to the final destination\n",
    "    if len(x) != 0:\n",
    "        for i in range (1,len(x)-1):\n",
    "            G.add_edge(x[i],x[i+1],stop=i)\n",
    "        G.add_edge(x[len(x)-1],x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color destination nodes\n",
    "#TODO: Vary destination color by benign or malicious designation\n",
    "\n",
    "colorCode=[]\n",
    "for x in G.nodes():\n",
    "    if (x in totalDest):\n",
    "        colorCode.append('blue')\n",
    "        \n",
    "    else:\n",
    "        colorCode.append('black')\n",
    "        \n",
    "print(len(G.nodes()), len(colorCode), cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "        'node_color': colorCode,\n",
    "        'node_size': 1,\n",
    "        'edge_color': 'grey',\n",
    "        'linewidths': 0,\n",
    "        'width': 0.1,\n",
    "    }\n",
    "plt.figure(figsize=(20,10),dpi=1000)\n",
    "nx.draw(G, **options)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('network_graph.jpg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_amazonei_tensorflow_p36)",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
