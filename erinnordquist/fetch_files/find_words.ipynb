{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used to create the vocabulary used in vectorize_final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pandas.io.json import json_normalize\n",
    "import cryptography\n",
    "import re\n",
    "from cryptography.fernet import Fernet\n",
    "import bs4\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "\n",
    "regex = re.compile( u'[？！｡。＂＃％＆＇¿（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏]', re.U)\n",
    "\n",
    "#ave_obj(regex, 'regex')\n",
    "#egex = load_obj('regex\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('&quot;','\\'',text)\n",
    "    text = re.sub('&amp;',' ',text)\n",
    "    text = re.sub(regex, ' ', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    #text = re.sub('-', ' ', text)\n",
    "    text = re.sub(r'\\'(?!\\')(.*)\\'',r'\\0', text)\n",
    "    text = re.sub(r'%\\S|\\s%|\\D%',' ', text)  \n",
    "    #text = re.sub(r'[,;{}\\(\\)<>\\/�\\?\\!_\\^\\|]', ' ', text)\n",
    "    text = re.sub(r'[\\]\\[\\s,:;{}\\(\\)<>\\/�\\?\\!_\\^\\|\\*\\+\\-=.&]', ' ', text)\n",
    "    \n",
    "    toks = re.split(r'\\s',text)\n",
    "    toks = [re.sub(r'((?![=]).*)=', r'\\0', x) for x in toks]\n",
    "    #toks = [re.sub(r'((?![.]).*)\\.', r'\\0', x) for x in toks]\n",
    "    #toks = [re.sub(r'(^\\.(?![.]).*)', r'\\0', x) for x in toks]\n",
    "    toks = [re.sub(r'\\\\','', x, re.U) for x in toks]   \n",
    "    toks = [re.sub(r'((?![\\]\\[]).*)\\]', r'\\0', x) for x in toks]\n",
    "    return sorted(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to get randomish sample from very large folders \n",
    "inds = random.sample(range(0,1000,2), k = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12714914\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715388\n",
      "12715388\n",
      "12715984\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12716113\n",
      "12716113\n",
      "12716113\n",
      "12716113\n",
      "12716164\n",
      "12716164\n",
      "12716164\n",
      "12716164\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "------------2019-04-12---------------\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "------------2019-04-11---------------\n",
      "12716447\n",
      "12716468\n",
      "12716468\n",
      "12716468\n",
      "12716595\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716926\n",
      "12716926\n",
      "12716927\n",
      "12716927\n",
      "------------2019-04-10---------------\n",
      "12718599\n",
      "12720566\n",
      "12722565\n",
      "12726581\n",
      "12729035\n",
      "12731097\n",
      "12734045\n",
      "12779725\n",
      "12790022\n",
      "12793279\n",
      "12794677\n",
      "12797359\n",
      "12800672\n",
      "12804960\n",
      "12807207\n",
      "12811850\n",
      "12815540\n",
      "12815952\n",
      "12819385\n",
      "12821842\n",
      "12828015\n",
      "12830425\n",
      "12833559\n",
      "12836191\n",
      "12838752\n",
      "12839779\n",
      "12842158\n",
      "12846777\n",
      "12849361\n",
      "12853505\n",
      "12856739\n",
      "12860539\n",
      "12862440\n",
      "12865124\n",
      "12867797\n",
      "12869550\n",
      "12871343\n",
      "12874283\n",
      "12879634\n",
      "12881276\n",
      "12883846\n",
      "12887273\n",
      "12889051\n",
      "12891248\n",
      "12893777\n",
      "12895941\n",
      "12900147\n",
      "12903565\n",
      "12906025\n",
      "12908456\n",
      "12910574\n",
      "12913847\n",
      "12917359\n",
      "12920705\n",
      "12928677\n",
      "12931274\n",
      "12933758\n",
      "12936821\n",
      "12942488\n",
      "12947490\n",
      "12952825\n",
      "12954999\n",
      "12961633\n",
      "12965431\n",
      "12967222\n",
      "12968698\n",
      "12984265\n",
      "12988653\n",
      "12990212\n",
      "12995759\n",
      "13000354\n",
      "13004641\n",
      "13009732\n",
      "13012600\n",
      "13016742\n",
      "13018863\n",
      "13020237\n",
      "13021092\n",
      "13023436\n",
      "13026623\n",
      "13029617\n",
      "13031778\n",
      "13038377\n",
      "13042923\n",
      "13045641\n",
      "13049469\n",
      "13052197\n",
      "13056020\n",
      "13058087\n",
      "13060141\n",
      "13062969\n",
      "13067178\n",
      "13071351\n",
      "13073228\n",
      "13076016\n",
      "13078158\n",
      "13081084\n",
      "13082561\n",
      "13084494\n",
      "13086011\n",
      "13089447\n",
      "13090778\n",
      "13097274\n",
      "13099974\n",
      "13103749\n",
      "13108927\n",
      "13110099\n",
      "13115571\n",
      "13116368\n",
      "13121995\n",
      "13122799\n",
      "13128262\n",
      "13129928\n",
      "13132011\n",
      "13139044\n",
      "13139866\n",
      "13146040\n",
      "13148254\n",
      "13149582\n",
      "13152277\n",
      "13154354\n",
      "13155309\n",
      "13157145\n",
      "13158950\n",
      "13160409\n",
      "13173689\n",
      "13174893\n",
      "13178025\n",
      "13181408\n",
      "13189215\n",
      "13192210\n",
      "13194522\n",
      "13197596\n",
      "13199300\n",
      "13202056\n",
      "13204227\n",
      "13205949\n",
      "13207793\n",
      "13213438\n",
      "13214868\n",
      "13216228\n",
      "13218527\n",
      "13220433\n",
      "13223797\n",
      "13225749\n",
      "13229662\n",
      "13232333\n",
      "13236069\n",
      "13238592\n",
      "13241894\n",
      "13243683\n",
      "13247279\n",
      "13252425\n",
      "13280140\n",
      "13282485\n",
      "13284347\n",
      "13287835\n",
      "13298991\n",
      "13300422\n",
      "13307745\n",
      "13310212\n",
      "13311631\n",
      "13314142\n",
      "13315584\n",
      "13318752\n",
      "13322836\n",
      "13327207\n",
      "13331073\n",
      "13336810\n",
      "13343772\n",
      "13348200\n",
      "13349954\n",
      "13352962\n",
      "13364313\n",
      "13366416\n",
      "13367771\n",
      "13371181\n",
      "13374778\n",
      "13376823\n",
      "13381129\n",
      "13388526\n",
      "13392629\n",
      "13397129\n",
      "13399626\n",
      "13401599\n",
      "13402608\n",
      "13407742\n",
      "13411126\n",
      "13412416\n",
      "13416892\n",
      "13429122\n",
      "13430566\n",
      "13432566\n",
      "13435007\n",
      "13439602\n",
      "13443070\n",
      "13448305\n",
      "13451206\n",
      "13454575\n",
      "13456359\n",
      "13457832\n",
      "13463839\n",
      "13466684\n",
      "13468808\n",
      "13472105\n",
      "13474229\n",
      "13476641\n",
      "13479525\n",
      "13481119\n",
      "13483583\n",
      "13486556\n",
      "13488405\n",
      "13492669\n",
      "13493988\n",
      "13495701\n",
      "13498594\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-87bbc8cc5e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#clean out symbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m            \u001b[0;31m# print(toks[10:15])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-45bade1380ce>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#toks = [re.sub(r'(^\\.(?![.]).*)', r'\\0', x) for x in toks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'((?![\\]\\[]).*)\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-45bade1380ce>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#toks = [re.sub(r'(^\\.(?![.]).*)', r'\\0', x) for x in toks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'((?![\\]\\[]).*)\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load data in and use it to construct a vocabularly where the tokens arwe stored with a count of how many documents they \n",
    "#have been present in so far\n",
    "#This currently filters based on url so the whole process doesn't have to run on URLs that have already been seen\n",
    "\n",
    "# Some dates are missing because they were missing the files I was trying to get\n",
    "date_batches = [['newbenigndata','2019-04-22','2019-04-23','2019-04-24','2019-04-25','2019-04-26','2019-04-27','2019-04-28','2019-04-29'],\n",
    "                ['2019-04-09','2019-04-08','2019-04-07'],\n",
    "                ['2019-04-30','2019-05-01','2019-05-02','2019-05-03','2019-05-04'],\n",
    "                ['2019-05-05','2019-05-06','2019-05-07','2019-05-08','2019-05-09','2019-05-10','2019-05-11','2019-05-12'],\n",
    "                ['2019-04-04','2019-04-03','2019-04-02','2019-04-01','2019-05-19','2019-05-20', '2019-04-21','2019-04-20','2019-04-19','2019-04-18','2019-04-17'],\n",
    "                ['2019-05-21','2019-05-22','2019-05-23','2019-05-24','2019-05-25','2019-05-26','2019-05-28'],\n",
    "                ['2019-05-29','2019-05-30','2019-05-31','2019-06-01','2019-06-02','2019-06-03','2019-06-04','2019-06-05'],\n",
    "                ['2019-04-12','2019-04-11','2019-04-10','newNONTORbenigndata'],\n",
    "                ['2019-06-06','2019-06-07','2019-06-08','2019-06-09','2019-06-10','2019-06-11','2019-06-12','2019-06-13']]\n",
    "#note that this bottom row is not included in here anymore\n",
    "dates = date_batches[7]+date_batches[6]+date_batches[4]+date_batches[5]+date_batches[0]+date_batches[2]+date_batches[3]+date_batches[1]\n",
    "#'2019-04-12','2019-04-16','2019-04-17','2019-04-18','2019-04-19','2019-04-20','2019-04-21]\n",
    "word_dict = {}\n",
    "indicators = []\n",
    "urls = [] \n",
    "for date in dates:\n",
    "    files = os.listdir('/data/data/'+date+'/enrichment/fetch_page')\n",
    "    top = len(files)\n",
    "    bot = 0\n",
    "    if top > 600:\n",
    "        lst = inds\n",
    "    else:\n",
    "        lst = range(bot,top)\n",
    "    for j in lst:\n",
    "        with open('/data/data/'+date+'/enrichment/fetch_page/'+files[j]) as d:\n",
    "            r = json.load(d)\n",
    "            try:\n",
    "                df = json_normalize(r['data'])\n",
    "            except:\n",
    "                break\n",
    "        try:\n",
    "            df = df[df['status_code'] == 200].reset_index(drop=True)\n",
    "            df = df[df['success']]\n",
    "        except:\n",
    "            df = df[df['success']]\n",
    "        #not worrying about labels right now\n",
    "        html_str = df['page_content'].copy()\n",
    "        \n",
    "        for i in range(len(html_str)):\n",
    "            if df.loc[i,'url'] in urls:\n",
    "                continue\n",
    "            else:\n",
    "                urls.append(df.loc[i, 'url'])\n",
    "            key = bytes( df.loc[i,'encryption_key'],encoding = 'UTF-8')\n",
    "            f = Fernet(key) #all rows of this df share this key\n",
    "            #decrypt string\n",
    "            text = f.decrypt(bytes(html_str[i],encoding='UTF-8'))\n",
    "            #clean out symbols\n",
    "            text = text.decode('utf8')\n",
    "            toks = tokenize(text)\n",
    "           # print(toks[10:15])\n",
    "            toks = set(toks)\n",
    "            for t in toks:\n",
    "                if t != '' and t != '\\x00' and len(t) > 1:\n",
    "                    if t in word_dict.keys():\n",
    "                        word_dict[t] = word_dict.get(t) + 1\n",
    "                        #print(t)\n",
    "                    else:\n",
    "                        word_dict[t] = 1\n",
    "                        #if '%' in t:\n",
    "                        #print(t)\n",
    "\n",
    "            #add to set\n",
    "        print(len(word_dict))\n",
    "         #end of for\n",
    "    #end of for\n",
    "    print('------------'+date+'---------------')\n",
    "#end of for\n",
    "\n",
    "\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the needed files\n",
    "save_obj(word_dict, 'plain_word_dict')\n",
    "pairs = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "save_obj(pairs, 'plain_sorted_kvpairs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
