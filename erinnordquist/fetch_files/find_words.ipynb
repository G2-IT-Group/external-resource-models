{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pandas.io.json import json_normalize\n",
    "import cryptography\n",
    "import re\n",
    "from cryptography.fernet import Fernet\n",
    "import bs4\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearing out all symbols got me up to 80%, but I'm still chasing that 82% I get with the file I made before. Now I'm trying introducing punctuation to see how it changes the number of terms and the accuracy of my random forest model. \n",
    "- no symbols -> 80% ; 14,139,420 unique tokens\n",
    "    - no symbols + l2 noramlization -> 78%\n",
    "- adding . back -> 78.4% ; 15,255,749\n",
    "- with .&# -> 80% ; 15,952,599\n",
    "- with *+-=.}&{#' ->79.56% ; 18,618,390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = random.sample(range(0,1000,2), k = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[202,\n",
       " 128,\n",
       " 8,\n",
       " 828,\n",
       " 176,\n",
       " 700,\n",
       " 798,\n",
       " 526,\n",
       " 492,\n",
       " 486,\n",
       " 934,\n",
       " 598,\n",
       " 550,\n",
       " 270,\n",
       " 942,\n",
       " 404,\n",
       " 868,\n",
       " 438,\n",
       " 566,\n",
       " 374,\n",
       " 536,\n",
       " 322,\n",
       " 882,\n",
       " 918,\n",
       " 122,\n",
       " 674,\n",
       " 710,\n",
       " 260,\n",
       " 278,\n",
       " 912,\n",
       " 458,\n",
       " 46,\n",
       " 108,\n",
       " 372,\n",
       " 198,\n",
       " 506,\n",
       " 742,\n",
       " 304,\n",
       " 442,\n",
       " 694,\n",
       " 998,\n",
       " 704,\n",
       " 440,\n",
       " 640,\n",
       " 102,\n",
       " 350,\n",
       " 854,\n",
       " 962,\n",
       " 120,\n",
       " 84,\n",
       " 324,\n",
       " 48,\n",
       " 682,\n",
       " 670,\n",
       " 714,\n",
       " 266,\n",
       " 696,\n",
       " 42,\n",
       " 90,\n",
       " 226,\n",
       " 818,\n",
       " 154,\n",
       " 606,\n",
       " 760,\n",
       " 448,\n",
       " 126,\n",
       " 814,\n",
       " 298,\n",
       " 946,\n",
       " 732,\n",
       " 952,\n",
       " 352,\n",
       " 516,\n",
       " 874,\n",
       " 970,\n",
       " 894,\n",
       " 192,\n",
       " 166,\n",
       " 924,\n",
       " 562,\n",
       " 200,\n",
       " 6,\n",
       " 582,\n",
       " 840,\n",
       " 844,\n",
       " 104,\n",
       " 152,\n",
       " 78,\n",
       " 56,\n",
       " 916,\n",
       " 156,\n",
       " 194,\n",
       " 772,\n",
       " 548,\n",
       " 18,\n",
       " 666,\n",
       " 644,\n",
       " 586,\n",
       " 620,\n",
       " 856,\n",
       " 914,\n",
       " 58,\n",
       " 4,\n",
       " 878,\n",
       " 480,\n",
       " 618,\n",
       " 376,\n",
       " 336,\n",
       " 652,\n",
       " 574,\n",
       " 98,\n",
       " 484,\n",
       " 604,\n",
       " 518,\n",
       " 184,\n",
       " 660,\n",
       " 634,\n",
       " 424,\n",
       " 230,\n",
       " 72,\n",
       " 740,\n",
       " 808,\n",
       " 542,\n",
       " 738,\n",
       " 886,\n",
       " 590,\n",
       " 22,\n",
       " 974,\n",
       " 832,\n",
       " 944,\n",
       " 872,\n",
       " 514,\n",
       " 756,\n",
       " 978,\n",
       " 262,\n",
       " 68,\n",
       " 446,\n",
       " 794,\n",
       " 754,\n",
       " 576,\n",
       " 300,\n",
       " 554,\n",
       " 74,\n",
       " 800,\n",
       " 340,\n",
       " 538,\n",
       " 460,\n",
       " 238,\n",
       " 770,\n",
       " 984,\n",
       " 534,\n",
       " 64,\n",
       " 288,\n",
       " 248,\n",
       " 116,\n",
       " 940,\n",
       " 0,\n",
       " 268,\n",
       " 150,\n",
       " 780,\n",
       " 496,\n",
       " 954,\n",
       " 494,\n",
       " 146,\n",
       " 976,\n",
       " 28,\n",
       " 806,\n",
       " 50,\n",
       " 932,\n",
       " 362,\n",
       " 470,\n",
       " 338,\n",
       " 552,\n",
       " 382,\n",
       " 286,\n",
       " 16,\n",
       " 210,\n",
       " 344,\n",
       " 204,\n",
       " 330,\n",
       " 686,\n",
       " 610,\n",
       " 366,\n",
       " 400,\n",
       " 476,\n",
       " 82,\n",
       " 276,\n",
       " 76,\n",
       " 412,\n",
       " 148,\n",
       " 182,\n",
       " 638,\n",
       " 60,\n",
       " 38,\n",
       " 758,\n",
       " 264,\n",
       " 444,\n",
       " 66,\n",
       " 728,\n",
       " 712,\n",
       " 708,\n",
       " 114,\n",
       " 172,\n",
       " 10,\n",
       " 930,\n",
       " 588,\n",
       " 386,\n",
       " 158,\n",
       " 654,\n",
       " 208,\n",
       " 466,\n",
       " 392,\n",
       " 390,\n",
       " 898,\n",
       " 62,\n",
       " 764,\n",
       " 464,\n",
       " 702,\n",
       " 986,\n",
       " 698,\n",
       " 858,\n",
       " 162,\n",
       " 820,\n",
       " 774,\n",
       " 318,\n",
       " 44,\n",
       " 178,\n",
       " 850,\n",
       " 564,\n",
       " 168,\n",
       " 468,\n",
       " 498,\n",
       " 306,\n",
       " 360,\n",
       " 612,\n",
       " 876,\n",
       " 32,\n",
       " 134,\n",
       " 358,\n",
       " 274,\n",
       " 632,\n",
       " 522,\n",
       " 532,\n",
       " 560,\n",
       " 124,\n",
       " 118,\n",
       " 332,\n",
       " 544,\n",
       " 778,\n",
       " 328,\n",
       " 852,\n",
       " 312,\n",
       " 462,\n",
       " 174,\n",
       " 140,\n",
       " 510,\n",
       " 256,\n",
       " 224,\n",
       " 730,\n",
       " 668,\n",
       " 280,\n",
       " 316,\n",
       " 112,\n",
       " 188,\n",
       " 910,\n",
       " 812,\n",
       " 430,\n",
       " 816,\n",
       " 822,\n",
       " 384,\n",
       " 26,\n",
       " 508,\n",
       " 326,\n",
       " 680,\n",
       " 546,\n",
       " 748,\n",
       " 186,\n",
       " 690,\n",
       " 296,\n",
       " 880,\n",
       " 106,\n",
       " 896,\n",
       " 568,\n",
       " 132,\n",
       " 614,\n",
       " 802,\n",
       " 334,\n",
       " 648,\n",
       " 206,\n",
       " 994,\n",
       " 948,\n",
       " 676,\n",
       " 926,\n",
       " 762,\n",
       " 138,\n",
       " 520,\n",
       " 20,\n",
       " 750,\n",
       " 908,\n",
       " 368]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)    \n",
    "\n",
    "regex = re.compile( u'[？！｡。＂＃％＆＇¿（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃《》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏]', re.U)\n",
    "\n",
    "#ave_obj(regex, 'regex')\n",
    "#egex = load_obj('regex\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('&quot;','\\'',text)\n",
    "    text = re.sub('&amp;',' ',text)\n",
    "    text = re.sub(regex, ' ', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    #text = re.sub('-', ' ', text)\n",
    "    text = re.sub(r'\\'(?!\\')(.*)\\'',r'\\0', text)\n",
    "    text = re.sub(r'%\\S|\\s%|\\D%',' ', text)  \n",
    "    #text = re.sub(r'[,;{}\\(\\)<>\\/�\\?\\!_\\^\\|]', ' ', text)\n",
    "    text = re.sub(r'[\\]\\[\\s,:;{}\\(\\)<>\\/�\\?\\!_\\^\\|\\*\\+\\-=.&]', ' ', text)\n",
    "    \n",
    "    toks = re.split(r'\\s',text)\n",
    "    toks = [re.sub(r'((?![=]).*)=', r'\\0', x) for x in toks]\n",
    "    #toks = [re.sub(r'((?![.]).*)\\.', r'\\0', x) for x in toks]\n",
    "    #toks = [re.sub(r'(^\\.(?![.]).*)', r'\\0', x) for x in toks]\n",
    "    toks = [re.sub(r'\\\\','', x, re.U) for x in toks]   \n",
    "    toks = [re.sub(r'((?![\\]\\[]).*)\\]', r'\\0', x) for x in toks]\n",
    "    return sorted(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12714914\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715325\n",
      "12715388\n",
      "12715388\n",
      "12715984\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12715987\n",
      "12716113\n",
      "12716113\n",
      "12716113\n",
      "12716113\n",
      "12716164\n",
      "12716164\n",
      "12716164\n",
      "12716164\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716165\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "------------2019-04-12---------------\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716167\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716303\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "12716447\n",
      "------------2019-04-11---------------\n",
      "12716447\n",
      "12716468\n",
      "12716468\n",
      "12716468\n",
      "12716595\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716600\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716610\n",
      "12716926\n",
      "12716926\n",
      "12716927\n",
      "12716927\n",
      "------------2019-04-10---------------\n",
      "12718599\n",
      "12720566\n",
      "12722565\n",
      "12726581\n",
      "12729035\n",
      "12731097\n",
      "12734045\n",
      "12779725\n",
      "12790022\n",
      "12793279\n",
      "12794677\n",
      "12797359\n",
      "12800672\n",
      "12804960\n",
      "12807207\n",
      "12811850\n",
      "12815540\n",
      "12815952\n",
      "12819385\n",
      "12821842\n",
      "12828015\n",
      "12830425\n",
      "12833559\n",
      "12836191\n",
      "12838752\n",
      "12839779\n",
      "12842158\n",
      "12846777\n",
      "12849361\n",
      "12853505\n",
      "12856739\n",
      "12860539\n",
      "12862440\n",
      "12865124\n",
      "12867797\n",
      "12869550\n",
      "12871343\n",
      "12874283\n",
      "12879634\n",
      "12881276\n",
      "12883846\n",
      "12887273\n",
      "12889051\n",
      "12891248\n",
      "12893777\n",
      "12895941\n",
      "12900147\n",
      "12903565\n",
      "12906025\n",
      "12908456\n",
      "12910574\n",
      "12913847\n",
      "12917359\n",
      "12920705\n",
      "12928677\n",
      "12931274\n",
      "12933758\n",
      "12936821\n",
      "12942488\n",
      "12947490\n",
      "12952825\n",
      "12954999\n",
      "12961633\n",
      "12965431\n",
      "12967222\n",
      "12968698\n",
      "12984265\n",
      "12988653\n",
      "12990212\n",
      "12995759\n",
      "13000354\n",
      "13004641\n",
      "13009732\n",
      "13012600\n",
      "13016742\n",
      "13018863\n",
      "13020237\n",
      "13021092\n",
      "13023436\n",
      "13026623\n",
      "13029617\n",
      "13031778\n",
      "13038377\n",
      "13042923\n",
      "13045641\n",
      "13049469\n",
      "13052197\n",
      "13056020\n",
      "13058087\n",
      "13060141\n",
      "13062969\n",
      "13067178\n",
      "13071351\n",
      "13073228\n",
      "13076016\n",
      "13078158\n",
      "13081084\n",
      "13082561\n",
      "13084494\n",
      "13086011\n",
      "13089447\n",
      "13090778\n",
      "13097274\n",
      "13099974\n",
      "13103749\n",
      "13108927\n",
      "13110099\n",
      "13115571\n",
      "13116368\n",
      "13121995\n",
      "13122799\n",
      "13128262\n",
      "13129928\n",
      "13132011\n",
      "13139044\n",
      "13139866\n",
      "13146040\n",
      "13148254\n",
      "13149582\n",
      "13152277\n",
      "13154354\n",
      "13155309\n",
      "13157145\n",
      "13158950\n",
      "13160409\n",
      "13173689\n",
      "13174893\n",
      "13178025\n",
      "13181408\n",
      "13189215\n",
      "13192210\n",
      "13194522\n",
      "13197596\n",
      "13199300\n",
      "13202056\n",
      "13204227\n",
      "13205949\n",
      "13207793\n",
      "13213438\n",
      "13214868\n",
      "13216228\n",
      "13218527\n",
      "13220433\n",
      "13223797\n",
      "13225749\n",
      "13229662\n",
      "13232333\n",
      "13236069\n",
      "13238592\n",
      "13241894\n",
      "13243683\n",
      "13247279\n",
      "13252425\n",
      "13280140\n",
      "13282485\n",
      "13284347\n",
      "13287835\n",
      "13298991\n",
      "13300422\n",
      "13307745\n",
      "13310212\n",
      "13311631\n",
      "13314142\n",
      "13315584\n",
      "13318752\n",
      "13322836\n",
      "13327207\n",
      "13331073\n",
      "13336810\n",
      "13343772\n",
      "13348200\n",
      "13349954\n",
      "13352962\n",
      "13364313\n",
      "13366416\n",
      "13367771\n",
      "13371181\n",
      "13374778\n",
      "13376823\n",
      "13381129\n",
      "13388526\n",
      "13392629\n",
      "13397129\n",
      "13399626\n",
      "13401599\n",
      "13402608\n",
      "13407742\n",
      "13411126\n",
      "13412416\n",
      "13416892\n",
      "13429122\n",
      "13430566\n",
      "13432566\n",
      "13435007\n",
      "13439602\n",
      "13443070\n",
      "13448305\n",
      "13451206\n",
      "13454575\n",
      "13456359\n",
      "13457832\n",
      "13463839\n",
      "13466684\n",
      "13468808\n",
      "13472105\n",
      "13474229\n",
      "13476641\n",
      "13479525\n",
      "13481119\n",
      "13483583\n",
      "13486556\n",
      "13488405\n",
      "13492669\n",
      "13493988\n",
      "13495701\n",
      "13498594\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-87bbc8cc5e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m#clean out symbols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m            \u001b[0;31m# print(toks[10:15])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-45bade1380ce>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#toks = [re.sub(r'(^\\.(?![.]).*)', r'\\0', x) for x in toks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'((?![\\]\\[]).*)\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-45bade1380ce>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#toks = [re.sub(r'(^\\.(?![.]).*)', r'\\0', x) for x in toks]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtoks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'((?![\\]\\[]).*)\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#rather than looping through everything, break it down and go through each item\n",
    "\n",
    "# Not included as all their files seem to be empty or they have no enrichment: \n",
    "    #4/5, 4/6, 4/13, 4/14, 4/15, 4/31, 5/13, 5/14, 5/15, 5/16, 5/17, 5/18, 7/4, 7/5, 7/6\n",
    "date_batches = [['newbenigndata','2019-04-22','2019-04-23','2019-04-24','2019-04-25','2019-04-26','2019-04-27','2019-04-28','2019-04-29'],\n",
    "                ['2019-04-09','2019-04-08','2019-04-07'],\n",
    "                ['2019-04-30','2019-05-01','2019-05-02','2019-05-03','2019-05-04'],\n",
    "                ['2019-05-05','2019-05-06','2019-05-07','2019-05-08','2019-05-09','2019-05-10','2019-05-11','2019-05-12'],\n",
    "                ['2019-04-04','2019-04-03','2019-04-02','2019-04-01','2019-05-19','2019-05-20', '2019-04-21','2019-04-20','2019-04-19','2019-04-18','2019-04-17'],\n",
    "                ['2019-05-21','2019-05-22','2019-05-23','2019-05-24','2019-05-25','2019-05-26','2019-05-28'],\n",
    "                ['2019-05-29','2019-05-30','2019-05-31','2019-06-01','2019-06-02','2019-06-03','2019-06-04','2019-06-05'],\n",
    "                ['2019-04-12','2019-04-11','2019-04-10','newNONTORbenigndata'],\n",
    "                ['2019-06-06','2019-06-07','2019-06-08','2019-06-09','2019-06-10','2019-06-11','2019-06-12','2019-06-13']]\n",
    "dates = date_batches[7]#+date_batches[6]+date_batches[4]+date_batches[5]+date_batches[0]+date_batches[2]+date_batches[3]+date_batches[1]\n",
    "#'2019-04-12','2019-04-16','2019-04-17','2019-04-18','2019-04-19','2019-04-20','2019-04-21]\n",
    "#word_dict = {}\n",
    "#indicators = []\n",
    "#urls = [] \n",
    "for date in dates:\n",
    "    files = os.listdir('/data/data/'+date+'/enrichment/fetch_page')\n",
    "    top = len(files)\n",
    "    bot = 0\n",
    "    if top > 600:\n",
    "        lst = inds\n",
    "    else:\n",
    "        lst = range(bot,top)\n",
    "    for j in lst:\n",
    "        with open('/data/data/'+date+'/enrichment/fetch_page/'+files[j]) as d:\n",
    "            r = json.load(d)\n",
    "            try:\n",
    "                df = json_normalize(r['data'])\n",
    "            except:\n",
    "                break\n",
    "        try:\n",
    "            df = df[df['status_code'] == 200].reset_index(drop=True)\n",
    "            df = df[df['success']]\n",
    "        except:\n",
    "            df = df[df['success']]\n",
    "        #not worrying about labels right now\n",
    "        html_str = df['page_content'].copy()\n",
    "        \n",
    "        for i in range(len(html_str)):\n",
    "            if df.loc[i,'url'] in urls:\n",
    "                continue\n",
    "            else:\n",
    "                urls.append(df.loc[i, 'url'])\n",
    "            key = bytes( df.loc[i,'encryption_key'],encoding = 'UTF-8')\n",
    "            f = Fernet(key) #all rows of this df share this key\n",
    "            #decrypt string\n",
    "            text = f.decrypt(bytes(html_str[i],encoding='UTF-8'))\n",
    "            #clean out symbols\n",
    "            text = text.decode('utf8')\n",
    "            toks = tokenize(text)\n",
    "           # print(toks[10:15])\n",
    "            toks = set(toks)\n",
    "            for t in toks:\n",
    "                if t != '' and t != '\\x00' and len(t) > 1:\n",
    "                    if t in word_dict.keys():\n",
    "                        word_dict[t] = word_dict.get(t) + 1\n",
    "                        #print(t)\n",
    "                    else:\n",
    "                        word_dict[t] = 1\n",
    "                        #if '%' in t:\n",
    "                        #print(t)\n",
    "\n",
    "            #add to set\n",
    "        print(len(word_dict))\n",
    "         #end of for\n",
    "    #end of for\n",
    "    print('------------'+date+'---------------')\n",
    "#end of for\n",
    "\n",
    "\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_obj(word_dict, 'plain_word_dict2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "save_obj(pairs, 'plain_sorted_kvpairs2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(load_obj('word_dict_url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(word_dict.items(), key=lambda x: x[1], reverse=True)[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "pairs = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "X = range(1, len(pairs)+1)\n",
    "Y = [b for a,b in pairs]\n",
    "Yl = [math.log(x) for x in Y]\n",
    "plt.plot(X[:15000],Yl[:15000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(word_dict, 'word_dict_orig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
