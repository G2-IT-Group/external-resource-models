{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the files that were not used to create the word list in the find_words notebook and vectorizes them so they can be fed through models. Still working on a way to effectively safe this numerical data, but I may only be able to do that with binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from pandas.io.json import json_normalize\n",
    "import cryptography\n",
    "import re\n",
    "from cryptography.fernet import Fernet\n",
    "import bs4\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics import edit_distance\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def tokenize(text):\n",
    "    text = re.sub('&quot;','\\'',text)\n",
    "    text = re.sub('&amp;','&',text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    text = re.sub(r'\\'(?!\\')(.*)\\'',r'\\0', text)\n",
    "    \n",
    "    toks = re.split(r'[\\s,:;{}\\(\\)<>\\/ï¿½]+',text.lower())\n",
    "    return sorted(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [a for a,b in load_obj('sorted_kvpairs_url')]\n",
    "vocab = sorted(vocab[:10000])#takes the top 10000 by freq and puts them in alphabetical/ascii order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------newNONTORbenigndata---------------\n",
      "------------2019-07-01---------------\n",
      "------------2019-07-02---------------\n",
      "------------2019-07-03---------------\n",
      "------------2019-07-07---------------\n",
      "------------2019-06-22---------------\n",
      "------------2019-06-23---------------\n",
      "------------2019-06-25---------------\n",
      "------------2019-06-26---------------\n",
      "------------2019-06-27---------------\n",
      "------------2019-06-28---------------\n",
      "------------2019-06-29---------------\n",
      "------------2019-06-30---------------\n",
      "------------2019-06-14---------------\n",
      "------------2019-06-15---------------\n",
      "------------2019-06-16---------------\n",
      "------------2019-06-17---------------\n",
      "------------2019-06-18---------------\n",
      "------------2019-06-19---------------\n",
      "------------2019-06-20---------------\n",
      "------------2019-06-21---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create corpus\n",
    "data = []\n",
    "labels = []\n",
    "indicators=[]\n",
    "url= []\n",
    "url_to_ind_distance = []\n",
    "text_len = []\n",
    "# Not included as all their files seem to be empty or they have no enrichment: \n",
    "    #4/5, 4/6, 4/13, 4/14, 4/15, 4/31, 5/13, 5/14, 5/15, 5/16, 5/17, 5/18, 7/4, 7/5, 7/6\n",
    "# Empty List serves as a place holder between the data used in find_words and the test data I'm using here\n",
    "date_batches = [['newbenigndata'],['2019-04-22','2019-04-23','2019-04-24','2019-04-25','2019-04-26','2019-04-27','2019-04-28','2019-04-29'],\n",
    "                ['2019-04-11','2019-04-12','2019-04-16','2019-04-17','2019-04-18','2019-04-19','2019-04-20','2019-04-21'],\n",
    "                ['2019-04-30','2019-05-01','2019-05-02','2019-05-03','2019-05-04'],\n",
    "                ['2019-05-05','2019-05-06','2019-05-07','2019-05-08','2019-05-09','2019-05-10','2019-05-11','2019-05-12'],\n",
    "                ['2019-05-19','2019-05-20'],\n",
    "                ['2019-05-21','2019-05-22','2019-05-23','2019-05-24','2019-05-25','2019-05-26','2019-05-27','2019-05-28'],\n",
    "                ['2019-05-29','2019-05-30','2019-05-31','2019-06-01','2019-06-02','2019-06-03','2019-06-04','2019-06-05'],\n",
    "                ['2019-06-06','2019-06-07','2019-06-08','2019-06-09','2019-06-10','2019-06-11','2019-06-12','2019-06-13'],[],\n",
    "                ['2019-06-14', '2019-06-15','2019-06-16', '2019-06-17','2019-06-18','2019-06-19', '2019-06-20', '2019-06-21'],\n",
    "                ['2019-06-22', '2019-06-23', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28','2019-06-29', '2019-06-30'],\n",
    "                ['2019-07-01','2019-07-02', '2019-07-03', '2019-07-07'],\n",
    "                ['newNONTORbenigndata']]\n",
    "dates = date_batches[-1]+date_batches[-2]+date_batches[-3]+date_batches[-4]#+date_batches[3]+date_batches[4]+date_batches[5]+date_batches[6]+date_batches[7]+date_batches[8] \n",
    "#'2019-04-12','2019-04-16','2019-04-17','2019-04-18','2019-04-19','2019-04-20','2019-04-21]\n",
    "for date in dates:\n",
    "    files = os.listdir('/data/data/'+date+'/enrichment/fetch_page')\n",
    "    top = len(files)\n",
    "    if top > 70:\n",
    "        top = 70\n",
    "    for j in range(top):\n",
    "        with open('/data/data/'+date+'/enrichment/fetch_page/'+files[j]) as d:\n",
    "            r = json.load(d)\n",
    "            try:\n",
    "                df = json_normalize(r['data'])\n",
    "            except:\n",
    "                break\n",
    "        try:\n",
    "            df = df[df['status_code'] == 200].reset_index(drop=True)\n",
    "        except:\n",
    "            df = df[df['success']]\n",
    "        #Need to determine label\n",
    "        html_str = df['page_content'].copy()\n",
    "        \n",
    "        for i in range(len(html_str)):\n",
    "            if df.loc[i,'url'] in url:\n",
    "                continue\n",
    "            else:\n",
    "                url.append(df.loc[i, 'url'])\n",
    "            if len(files[j]) > 10:\n",
    "                labels += [1]\n",
    "            else:\n",
    "                labels += [0]\n",
    "            key = bytes( df.loc[i,'encryption_key'],encoding = 'UTF-8')\n",
    "            f = Fernet(key) \n",
    "            #decrypt string\n",
    "            text = f.decrypt(bytes(html_str[i],encoding='UTF-8'))\n",
    "            #clean out html\n",
    "            text = text.decode('utf8')\n",
    "            text_len.append(len(text))\n",
    "            url_to_ind_distance.append(edit_distance(df.loc[i,'url'],df.loc[i,'indicator']))\n",
    "\n",
    "            toks = tokenize(text)\n",
    "            #need to create vector \n",
    "            count = Counter()\n",
    "            for tok in toks:\n",
    "                count[tok] += 1\n",
    "            vec = []\n",
    "            for v in vocab:\n",
    "                vec = np.append(vec, [count[v]])\n",
    "            data.append(vec)\n",
    "                \n",
    "            \n",
    "            \n",
    "         #end of for\n",
    "    #end of for\n",
    "    print('------------'+date+'---------------')\n",
    "#end of for\n",
    "data = np.row_stack(data)\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4589, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4589, 10001)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stick the labels on to make sure they stay properly matched as I turn data into a DataFrame for shuffling and balancing\n",
    "print(data.shape)\n",
    "np.column_stack([data,labels]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1711, 10003)\n",
      "(2261, 10003)\n",
      "(1711, 10003)\n",
      "(1712, 10003)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame( data,columns=vocab)#np.column_stack([data,labels])\n",
    "X['url_to_ind'] = url_to_ind_distance\n",
    "X['text_len'] = text_len\n",
    "X['unsafe'] = labels\n",
    "X = X.drop_duplicates()\n",
    "X1 = X[X['unsafe']==1].sample(frac=1)\n",
    "print(X1.shape)\n",
    "X0 = X[X['unsafe']==0].sample(frac=1)\n",
    "print(X0.shape)\n",
    "if(X0.shape[0] < X1.shape[0]):\n",
    "    X1 = X1.reset_index(drop=True).loc[:(X0.shape[0]),:]\n",
    "else: \n",
    "    X0 = X0.reset_index(drop=True).loc[:(X1.shape[0]),:]\n",
    "print(X1.shape)\n",
    "print(X0.shape)\n",
    "temp_df = pd.concat([X0,X1]).sample(frac=1)\n",
    "X = temp_df.drop(columns=['unsafe'])\n",
    "Y = temp_df['unsafe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.7956204379562044\n",
      "('script', 0.013565347095304641)\n",
      "('meta', 0.009802154467416684)\n",
      "('a', 0.008024725534680064)\n",
      "('function', 0.00783414945850082)\n",
      "('div', 0.007069130298423087)\n",
      "('target=_blank', 0.006573250150978455)\n",
      "('s', 0.005870086403634259)\n",
      "('img', 0.005797029494810169)\n",
      "('href=https', 0.005655468018594915)\n",
      "('name=keywords', 0.005588757629589856)\n",
      "('new', 0.005530736712598492)\n",
      "('li', 0.005476396168960012)\n",
      "('rel=stylesheet', 0.005230383715202424)\n",
      "('[0]', 0.005133533066287969)\n",
      "('javascript', 0.004997478263105494)\n",
      "('news', 0.004958243150430527)\n",
      "('1', 0.004196207535283486)\n",
      "('arguments', 0.003456885142350018)\n",
      "('href=http', 0.003334610453732152)\n",
      "('type=text', 0.0032777175979914392)\n",
      "('event', 0.003080532639160124)\n",
      "('user', 0.0030583767006813417)\n",
      "('favicon.ico', 0.003058203777505793)\n",
      "('link', 0.002984832700592136)\n",
      "('twitter.com', 0.002972948778828304)\n",
      "('else', 0.0029537511845318942)\n",
      "('null', 0.002813971133442428)\n",
      "('\\x00', 0.0027961644690243093)\n",
      "('var', 0.002765855504332458)\n",
      "('in', 0.0027075530437294403)\n",
      "('[]', 0.0026630391638960897)\n",
      "('title', 0.0026599715142831028)\n",
      "('true', 0.0026224148870596935)\n",
      "('from', 0.0026153880386407596)\n",
      "('catch', 0.002605944426765943)\n",
      "('html', 0.0026010787167397575)\n",
      "('=', 0.0025216411276145507)\n",
      "('google', 0.0025136218131878484)\n",
      "('search', 0.002485757100177048)\n",
      "('o', 0.0024409579553020346)\n",
      "('image', 0.002372478341655697)\n",
      "('.gettime', 0.0023324723890331975)\n",
      "('www.facebook.com', 0.0023137744331690802)\n",
      "('for', 0.00228145197597175)\n",
      "('r', 0.002263836265234849)\n",
      "('date', 0.0022633754812775653)\n",
      "('return', 0.0022552897786500404)\n",
      "('wp-content', 0.002235850281881941)\n",
      "('2019', 0.0022307373558258267)\n",
      "('window._wpemojisettings', 0.002214772956916684)\n",
      "('http-equiv=refresh', 0.0021352690501486244)\n",
      "('head', 0.002134803189035182)\n",
      "('ul', 0.002130476685307447)\n",
      "('apps', 0.0021077303326009354)\n",
      "('c.supports.everything||', 0.002080052197630561)\n",
      "('10', 0.002048584875197489)\n",
      "('span', 0.0020228538751233915)\n",
      "('hidden', 0.0020047204157479415)\n",
      "('0', 0.0019921111346469867)\n",
      "('document.createelement', 0.0019852588220375896)\n",
      "('app', 0.001976987859250341)\n",
      "('c.domready=!1', 0.0019471119836304202)\n",
      "('video', 0.0019376560507776343)\n",
      "('56418', 0.0019002377574528768)\n",
      "('3', 0.0018924774836494396)\n",
      "('c.defer=c.type=text', 0.0018591972154622682)\n",
      "('if', 0.0018180525735733075)\n",
      "('content', 0.0018127018157949443)\n",
      "('||', 0.001788332767418675)\n",
      "('i', 0.0017845736975833162)\n",
      "('data', 0.0017455911089621172)\n",
      "('title=rsd', 0.0017289694216191796)\n",
      "('js', 0.001724763120308638)\n",
      "('56423', 0.0017069650308657465)\n",
      "('n', 0.001701181092607201)\n",
      "('name=description', 0.0016839164345727336)\n",
      "('input', 0.0016809594433057989)\n",
      "('form', 0.00167795710275761)\n",
      "('body', 0.001677749756943296)\n",
      "('-', 0.0016186543260580662)\n",
      "('english', 0.0015981873434634721)\n",
      "('h2', 0.0015954671396203012)\n",
      "('and', 0.0015893818921596252)\n",
      "('content=0', 0.0015885115791259361)\n",
      "('p', 0.0015875067068112543)\n",
      "('57332', 0.0015668922307440973)\n",
      "('site', 0.001543980586866675)\n",
      "('about', 0.0015037284309908745)\n",
      "('-0.1em', 0.0014925403892144206)\n",
      "('css', 0.0014617387713512918)\n",
      "('!--', 0.0014452262104938034)\n",
      "('2', 0.0014449559937778043)\n",
      "('br', 0.0014175577860579109)\n",
      "('feed', 0.001412504929587478)\n",
      "('help', 0.00140576982141593)\n",
      "('style=width', 0.0013989722913911602)\n",
      "('--', 0.001392615399097024)\n",
      "('type=hidden', 0.001385657834967881)\n",
      "('images', 0.0013792692712370686)\n",
      "('\\\\', 0.0013684104862375173)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80       688\n",
      "          1       0.79      0.79      0.79       682\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X = data\n",
    "#Y = labels\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size= 0.6, test_size=0.4)\n",
    "forest = RandomForestClassifier(n_estimators=80)\n",
    "forest.fit(X_train,Y_train)\n",
    "print()\n",
    "print(forest.score(X_test,Y_test))\n",
    "print(*(sorted(list(zip(vocab,forest.feature_importances_)), key=lambda x: x[1],reverse=True))[:100], sep = '\\n')\n",
    "print(classification_report(Y_test,forest.predict(X_test)))\n",
    "\n",
    "#forest = RandomForestRegressor(n_estimators=80,random_state=13)\n",
    "#forest.fit(X_train,Y_train)\n",
    "#print(forest.score(X_test,Y_test))\n",
    "#print(*(sorted(list(zip(vocab,forest.feature_importances_)), key=lambda x: x[1],reverse=True))[:100], sep = '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7832116788321168\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.75      0.78       688\n",
      "          1       0.77      0.81      0.79       682\n",
      "\n",
      "avg / total       0.78      0.78      0.78      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=13)\n",
    "clf.fit(X_train,Y_train)\n",
    "print(clf.score(X_test,Y_test))\n",
    "print(classification_report(Y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.73688905\n",
      "Iteration 2, loss = 5.96237829\n",
      "Iteration 3, loss = 3.74173931\n",
      "Iteration 4, loss = 3.35131648\n",
      "Iteration 5, loss = 4.23664669\n",
      "Iteration 6, loss = 3.65870737\n",
      "Iteration 7, loss = 5.34645568\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "0.6620437956204379\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.93      0.73       688\n",
      "          1       0.85      0.39      0.54       682\n",
      "\n",
      "avg / total       0.73      0.66      0.64      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(verbose=True, batch_size= 9, random_state = 15)\n",
    "clf.fit(X_train,Y_train)\n",
    "print(clf.score(X_test,Y_test))\n",
    "print(classification_report(Y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 7.29881352\n",
      "Iteration 2, loss = 7.10488683\n",
      "Iteration 3, loss = 4.75932864\n",
      "Iteration 4, loss = 3.59717582\n",
      "Iteration 5, loss = 3.20208511\n",
      "Iteration 6, loss = 4.80790429\n",
      "Iteration 7, loss = 3.94758288\n",
      "Iteration 8, loss = 4.19771202\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "0.7532846715328467\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.85      0.78       688\n",
      "          1       0.81      0.66      0.73       682\n",
      "\n",
      "avg / total       0.76      0.75      0.75      1370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(verbose=True, batch_size= 9, random_state = 13)\n",
    "clf.fit(X_train,Y_train)\n",
    "print(clf.score(X_test,Y_test))\n",
    "print(classification_report(Y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7542799597180262\n",
      "0.771399798590131\n",
      "0.7900302114803626\n",
      "0.7537764350453172\n",
      "0.8081570996978852\n",
      "0.7804632426988922\n",
      "0.7719033232628398\n",
      "0.7754279959718026\n",
      "0.7779456193353474\n",
      "0.5140986908358509\n",
      "0.622356495468278\n",
      "0.7829808660624371\n",
      "0.7829808660624371\n",
      "0.797079556898288\n",
      "0.7865055387713998\n",
      "0.6389728096676737\n",
      "0.607754279959718\n",
      "0.43303121852970794\n",
      "0.7109768378650554\n",
      "0.6178247734138973\n",
      "0.7804632426988922\n",
      "0.7739174219536757\n",
      "0.7537764350453172\n",
      "0.7819738167170192\n",
      "0.7774420946626385\n",
      "0.7925478348439073\n",
      "0.7804632426988922\n",
      "0.6430010070493454\n",
      "0.7824773413897281\n",
      "0.7099697885196374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "for i in range(0,30):\n",
    "    X = pd.DataFrame( data,columns=vocab)#np.column_stack([data,labels])\n",
    "    X['url_to_ind'] = url_to_ind_distance\n",
    "    X['text_len'] = text_len\n",
    "    X['unsafe'] = labels\n",
    "    X = X.drop_duplicates()\n",
    "    X1 = X[X['unsafe']==1].sample(frac=1)\n",
    "    X0 = X[X['unsafe']==0].sample(frac=1)\n",
    "    if(X0.shape[0] < X1.shape[0]):\n",
    "        X1 = X1.reset_index(drop=True).loc[:(X0.shape[0]),:]\n",
    "    else: \n",
    "        X0 - X0.reset_index(drop=True).loc[:(X1.shape[0]),:]\n",
    "    temp_df = pd.concat([X0,X1]).sample(frac=1) \n",
    "    X = temp_df.drop(columns=['unsafe'])\n",
    "    Y = temp_df['unsafe']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size= 0.5, test_size=0.5, random_state=10*i)\n",
    "    clf = MLPClassifier(batch_size= 9, random_state = i)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    print(clf.score(X_test,Y_test))\n",
    "    #print(classification_report(Y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get new X and Y\n",
    "X = pd.DataFrame( data,columns=vocab)#np.column_stack([data,labels])\n",
    "X['url_to_ind'] = url_to_ind_distance\n",
    "X['text_len'] = text_len\n",
    "X['unsafe'] = labels\n",
    "X = X.drop_duplicates()\n",
    "X1 = X[X['unsafe']==1].sample(frac=1)\n",
    "X0 = X[X['unsafe']==0].sample(frac=1)\n",
    "if(X0.shape[0] < X1.shape[0]):\n",
    "    X1 = X1.reset_index(drop=True).loc[:(X0.shape[0]),:]\n",
    "else: \n",
    "    X0 - X0.reset_index(drop=True).loc[:(X1.shape[0]),:]\n",
    "temp_df = pd.concat([X0,X1]).sample(frac=1).drop_duplicates() \n",
    "X = temp_df.drop(columns=['unsafe'])\n",
    "Y = temp_df['unsafe']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size= 0.60, test_size=0.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Keras to try and improve on this 86-88% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 12)                120036    \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 120,049\n",
      "Trainable params: 120,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(12, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1986 samples, validate on 1986 samples\n",
      "Epoch 1/130\n",
      "1986/1986 [==============================] - 4s 2ms/step - loss: 1.1553 - acc: 0.5257 - val_loss: 0.6906 - val_acc: 0.5650\n",
      "Epoch 2/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.7268 - acc: 0.5725 - val_loss: 0.6875 - val_acc: 0.5650\n",
      "Epoch 3/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.7772 - acc: 0.5715 - val_loss: 0.6861 - val_acc: 0.5650\n",
      "Epoch 4/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.7825 - acc: 0.5725 - val_loss: 0.6853 - val_acc: 0.5650\n",
      "Epoch 5/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.7281 - acc: 0.5755 - val_loss: 0.6849 - val_acc: 0.5650\n",
      "Epoch 6/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.7123 - acc: 0.5725 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 7/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.7205 - acc: 0.5735 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 8/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.7071 - acc: 0.5740 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 9/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.7103 - acc: 0.5720 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 10/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6870 - acc: 0.5730 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 11/130\n",
      "1986/1986 [==============================] - 2s 772us/step - loss: 0.6892 - acc: 0.5730 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 12/130\n",
      "1986/1986 [==============================] - 2s 772us/step - loss: 0.6882 - acc: 0.5735 - val_loss: 0.6847 - val_acc: 0.5650\n",
      "Epoch 13/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.6817 - acc: 0.5740 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 14/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.7017 - acc: 0.5735 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 15/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.7659 - acc: 0.5700 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 16/130\n",
      "1986/1986 [==============================] - 2s 780us/step - loss: 0.6885 - acc: 0.5760 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 17/130\n",
      "1986/1986 [==============================] - 2s 785us/step - loss: 0.6970 - acc: 0.5730 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 18/130\n",
      "1986/1986 [==============================] - 2s 786us/step - loss: 0.6914 - acc: 0.5735 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 19/130\n",
      "1986/1986 [==============================] - 2s 810us/step - loss: 0.6813 - acc: 0.5735 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 20/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6826 - acc: 0.5735 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 21/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.6820 - acc: 0.5735 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 22/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6896 - acc: 0.5735 - val_loss: 0.6848 - val_acc: 0.5650\n",
      "Epoch 23/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.7270 - acc: 0.5725 - val_loss: 0.6848 - val_acc: 0.5645\n",
      "Epoch 24/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.7093 - acc: 0.5740 - val_loss: 0.6845 - val_acc: 0.5639\n",
      "Epoch 25/130\n",
      "1986/1986 [==============================] - 2s 772us/step - loss: 0.6921 - acc: 0.5765 - val_loss: 0.6844 - val_acc: 0.5655\n",
      "Epoch 26/130\n",
      "1986/1986 [==============================] - 2s 780us/step - loss: 0.6811 - acc: 0.5760 - val_loss: 0.6844 - val_acc: 0.5660\n",
      "Epoch 27/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.6916 - acc: 0.5775 - val_loss: 0.6843 - val_acc: 0.5670\n",
      "Epoch 28/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.6885 - acc: 0.5775 - val_loss: 0.6843 - val_acc: 0.5680\n",
      "Epoch 29/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.7029 - acc: 0.5775 - val_loss: 0.6842 - val_acc: 0.5690\n",
      "Epoch 30/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6919 - acc: 0.5760 - val_loss: 0.6850 - val_acc: 0.5655\n",
      "Epoch 31/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6967 - acc: 0.5765 - val_loss: 0.6850 - val_acc: 0.5660\n",
      "Epoch 32/130\n",
      "1986/1986 [==============================] - 2s 771us/step - loss: 0.7036 - acc: 0.5760 - val_loss: 0.6851 - val_acc: 0.5660\n",
      "Epoch 33/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.6877 - acc: 0.5770 - val_loss: 0.6851 - val_acc: 0.5665\n",
      "Epoch 34/130\n",
      "1986/1986 [==============================] - 2s 790us/step - loss: 0.7125 - acc: 0.5760 - val_loss: 0.6851 - val_acc: 0.5665\n",
      "Epoch 35/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6800 - acc: 0.5780 - val_loss: 0.6852 - val_acc: 0.5665\n",
      "Epoch 36/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.6800 - acc: 0.5775 - val_loss: 0.6852 - val_acc: 0.5665\n",
      "Epoch 37/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.6880 - acc: 0.5765 - val_loss: 0.6852 - val_acc: 0.5665\n",
      "Epoch 38/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.6870 - acc: 0.5770 - val_loss: 0.6852 - val_acc: 0.5675\n",
      "Epoch 39/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6804 - acc: 0.5785 - val_loss: 0.6852 - val_acc: 0.5675\n",
      "Epoch 40/130\n",
      "1986/1986 [==============================] - 2s 781us/step - loss: 0.6797 - acc: 0.5775 - val_loss: 0.6852 - val_acc: 0.5675\n",
      "Epoch 41/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.6790 - acc: 0.5785 - val_loss: 0.6851 - val_acc: 0.5675\n",
      "Epoch 42/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6791 - acc: 0.5775 - val_loss: 0.6849 - val_acc: 0.5675\n",
      "Epoch 43/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.6934 - acc: 0.5785 - val_loss: 0.6848 - val_acc: 0.5675\n",
      "Epoch 44/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.6957 - acc: 0.5765 - val_loss: 0.6847 - val_acc: 0.5675\n",
      "Epoch 45/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6867 - acc: 0.5785 - val_loss: 0.6850 - val_acc: 0.5680\n",
      "Epoch 46/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6861 - acc: 0.5775 - val_loss: 0.6848 - val_acc: 0.5680\n",
      "Epoch 47/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6870 - acc: 0.5775 - val_loss: 0.6850 - val_acc: 0.5680\n",
      "Epoch 48/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6865 - acc: 0.5775 - val_loss: 0.6848 - val_acc: 0.5680\n",
      "Epoch 49/130\n",
      "1986/1986 [==============================] - 2s 786us/step - loss: 0.6788 - acc: 0.5785 - val_loss: 0.6850 - val_acc: 0.5680\n",
      "Epoch 50/130\n",
      "1986/1986 [==============================] - 2s 781us/step - loss: 0.6782 - acc: 0.5785 - val_loss: 0.6854 - val_acc: 0.5680\n",
      "Epoch 51/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6797 - acc: 0.5770 - val_loss: 0.6852 - val_acc: 0.5680\n",
      "Epoch 52/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6780 - acc: 0.5780 - val_loss: 0.6848 - val_acc: 0.5680\n",
      "Epoch 53/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.6790 - acc: 0.5775 - val_loss: 0.6846 - val_acc: 0.5685\n",
      "Epoch 54/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.6784 - acc: 0.5785 - val_loss: 0.6846 - val_acc: 0.5685\n",
      "Epoch 55/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6786 - acc: 0.5780 - val_loss: 0.6848 - val_acc: 0.5685\n",
      "Epoch 56/130\n",
      "1986/1986 [==============================] - 2s 769us/step - loss: 0.6785 - acc: 0.5780 - val_loss: 0.6848 - val_acc: 0.5685\n",
      "Epoch 57/130\n",
      "1986/1986 [==============================] - 2s 780us/step - loss: 0.6783 - acc: 0.5785 - val_loss: 0.6846 - val_acc: 0.5685\n",
      "Epoch 58/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6857 - acc: 0.5785 - val_loss: 0.6847 - val_acc: 0.5685\n",
      "Epoch 59/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6783 - acc: 0.5785 - val_loss: 0.6849 - val_acc: 0.5685\n",
      "Epoch 60/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6783 - acc: 0.5785 - val_loss: 0.6850 - val_acc: 0.5685\n",
      "Epoch 61/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.6864 - acc: 0.5770 - val_loss: 0.6849 - val_acc: 0.5685\n",
      "Epoch 62/130\n",
      "1986/1986 [==============================] - 2s 770us/step - loss: 0.6931 - acc: 0.5791 - val_loss: 0.6849 - val_acc: 0.5685\n",
      "Epoch 63/130\n",
      "1986/1986 [==============================] - 2s 772us/step - loss: 0.6781 - acc: 0.5785 - val_loss: 0.6850 - val_acc: 0.5685\n",
      "Epoch 64/130\n",
      "1986/1986 [==============================] - 2s 780us/step - loss: 0.6776 - acc: 0.5791 - val_loss: 0.6852 - val_acc: 0.5685\n",
      "Epoch 65/130\n",
      "1986/1986 [==============================] - 2s 787us/step - loss: 0.6773 - acc: 0.5796 - val_loss: 0.6850 - val_acc: 0.5685\n",
      "Epoch 66/130\n",
      "1986/1986 [==============================] - 2s 784us/step - loss: 0.6781 - acc: 0.5791 - val_loss: 0.6849 - val_acc: 0.5685\n",
      "Epoch 67/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6766 - acc: 0.5811 - val_loss: 0.6844 - val_acc: 0.5710\n",
      "Epoch 68/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.7327 - acc: 0.5775 - val_loss: 0.6848 - val_acc: 0.5700\n",
      "Epoch 69/130\n",
      "1986/1986 [==============================] - 2s 790us/step - loss: 0.6808 - acc: 0.5796 - val_loss: 0.6851 - val_acc: 0.5690\n",
      "Epoch 70/130\n",
      "1986/1986 [==============================] - 2s 785us/step - loss: 0.6761 - acc: 0.5811 - val_loss: 0.6849 - val_acc: 0.5700\n",
      "Epoch 71/130\n",
      "1986/1986 [==============================] - 2s 807us/step - loss: 0.6921 - acc: 0.5796 - val_loss: 0.6846 - val_acc: 0.5700\n",
      "Epoch 72/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6914 - acc: 0.5801 - val_loss: 0.6843 - val_acc: 0.5705\n",
      "Epoch 73/130\n",
      "1986/1986 [==============================] - 2s 794us/step - loss: 0.7120 - acc: 0.5826 - val_loss: 0.6854 - val_acc: 0.5690\n",
      "Epoch 74/130\n",
      "1986/1986 [==============================] - 2s 786us/step - loss: 0.6758 - acc: 0.5816 - val_loss: 0.6848 - val_acc: 0.5705\n",
      "Epoch 75/130\n",
      "1986/1986 [==============================] - 2s 807us/step - loss: 0.7056 - acc: 0.5796 - val_loss: 0.6857 - val_acc: 0.5685\n",
      "Epoch 76/130\n",
      "1986/1986 [==============================] - 2s 919us/step - loss: 0.6836 - acc: 0.5811 - val_loss: 0.6859 - val_acc: 0.5685\n",
      "Epoch 77/130\n",
      "1986/1986 [==============================] - 2s 846us/step - loss: 0.6933 - acc: 0.5806 - val_loss: 0.6851 - val_acc: 0.5710\n",
      "Epoch 78/130\n",
      "1986/1986 [==============================] - 2s 787us/step - loss: 0.6913 - acc: 0.5801 - val_loss: 0.6855 - val_acc: 0.5695\n",
      "Epoch 79/130\n",
      "1986/1986 [==============================] - 2s 787us/step - loss: 0.6997 - acc: 0.5791 - val_loss: 0.6852 - val_acc: 0.5700\n",
      "Epoch 80/130\n",
      "1986/1986 [==============================] - 2s 785us/step - loss: 0.6747 - acc: 0.5826 - val_loss: 0.6849 - val_acc: 0.5710\n",
      "Epoch 81/130\n",
      "1986/1986 [==============================] - 2s 787us/step - loss: 0.6833 - acc: 0.5811 - val_loss: 0.6848 - val_acc: 0.5710\n",
      "Epoch 82/130\n",
      "1986/1986 [==============================] - 2s 787us/step - loss: 0.6795 - acc: 0.5796 - val_loss: 0.6850 - val_acc: 0.5705\n",
      "Epoch 83/130\n",
      "1986/1986 [==============================] - 2s 790us/step - loss: 0.6910 - acc: 0.5806 - val_loss: 0.6849 - val_acc: 0.5710\n",
      "Epoch 84/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6766 - acc: 0.5806 - val_loss: 0.6851 - val_acc: 0.5705\n",
      "Epoch 85/130\n",
      "1986/1986 [==============================] - 2s 772us/step - loss: 0.6845 - acc: 0.5796 - val_loss: 0.6844 - val_acc: 0.5710\n",
      "Epoch 86/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.7115 - acc: 0.5856 - val_loss: 0.6841 - val_acc: 0.5710\n",
      "Epoch 87/130\n",
      "1986/1986 [==============================] - 2s 788us/step - loss: 0.7034 - acc: 0.5841 - val_loss: 0.6849 - val_acc: 0.5705\n",
      "Epoch 88/130\n",
      "1986/1986 [==============================] - 2s 777us/step - loss: 0.6758 - acc: 0.5816 - val_loss: 0.6844 - val_acc: 0.5715\n",
      "Epoch 89/130\n",
      "1986/1986 [==============================] - 2s 781us/step - loss: 0.6816 - acc: 0.5836 - val_loss: 0.6842 - val_acc: 0.5710\n",
      "Epoch 90/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6846 - acc: 0.5816 - val_loss: 0.6843 - val_acc: 0.5710\n",
      "Epoch 91/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.7246 - acc: 0.5846 - val_loss: 0.6846 - val_acc: 0.5710\n",
      "Epoch 92/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6827 - acc: 0.5821 - val_loss: 0.6864 - val_acc: 0.5685\n",
      "Epoch 93/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6758 - acc: 0.5816 - val_loss: 0.6864 - val_acc: 0.5690\n",
      "Epoch 94/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.6765 - acc: 0.5806 - val_loss: 0.6864 - val_acc: 0.5695\n",
      "Epoch 95/130\n",
      "1986/1986 [==============================] - 2s 811us/step - loss: 0.6759 - acc: 0.5816 - val_loss: 0.6855 - val_acc: 0.5705\n",
      "Epoch 96/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.7072 - acc: 0.5891 - val_loss: 0.6855 - val_acc: 0.5710\n",
      "Epoch 97/130\n",
      "1986/1986 [==============================] - 2s 780us/step - loss: 0.6976 - acc: 0.5851 - val_loss: 0.6849 - val_acc: 0.5705\n",
      "Epoch 98/130\n",
      "1986/1986 [==============================] - 2s 786us/step - loss: 0.7429 - acc: 0.5851 - val_loss: 0.6862 - val_acc: 0.5685\n",
      "Epoch 99/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6841 - acc: 0.5806 - val_loss: 0.6862 - val_acc: 0.5685\n",
      "Epoch 100/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6837 - acc: 0.5801 - val_loss: 0.6863 - val_acc: 0.5685\n",
      "Epoch 101/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6853 - acc: 0.5785 - val_loss: 0.6863 - val_acc: 0.5685\n",
      "Epoch 102/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6768 - acc: 0.5806 - val_loss: 0.6865 - val_acc: 0.5685\n",
      "Epoch 103/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6769 - acc: 0.5801 - val_loss: 0.6867 - val_acc: 0.5685\n",
      "Epoch 104/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6815 - acc: 0.5816 - val_loss: 0.6870 - val_acc: 0.5685\n",
      "Epoch 105/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.6769 - acc: 0.5801 - val_loss: 0.6871 - val_acc: 0.5685\n",
      "Epoch 106/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6767 - acc: 0.5806 - val_loss: 0.6872 - val_acc: 0.5685\n",
      "Epoch 107/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6835 - acc: 0.5811 - val_loss: 0.6874 - val_acc: 0.5685\n",
      "Epoch 108/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6846 - acc: 0.5796 - val_loss: 0.6875 - val_acc: 0.5685\n",
      "Epoch 109/130\n",
      "1986/1986 [==============================] - 2s 772us/step - loss: 0.6769 - acc: 0.5801 - val_loss: 0.6877 - val_acc: 0.5685\n",
      "Epoch 110/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6766 - acc: 0.5806 - val_loss: 0.6878 - val_acc: 0.5685\n",
      "Epoch 111/130\n",
      "1986/1986 [==============================] - 2s 794us/step - loss: 0.6845 - acc: 0.5801 - val_loss: 0.6881 - val_acc: 0.5685\n",
      "Epoch 112/130\n",
      "1986/1986 [==============================] - 2s 803us/step - loss: 0.6763 - acc: 0.5811 - val_loss: 0.6883 - val_acc: 0.5690\n",
      "Epoch 113/130\n",
      "1986/1986 [==============================] - 2s 783us/step - loss: 0.6764 - acc: 0.5801 - val_loss: 0.6876 - val_acc: 0.5695\n",
      "Epoch 114/130\n",
      "1986/1986 [==============================] - 2s 784us/step - loss: 0.6829 - acc: 0.5816 - val_loss: 0.6875 - val_acc: 0.5690\n",
      "Epoch 115/130\n",
      "1986/1986 [==============================] - 2s 774us/step - loss: 0.6842 - acc: 0.5801 - val_loss: 0.6874 - val_acc: 0.5695\n",
      "Epoch 116/130\n",
      "1986/1986 [==============================] - 2s 773us/step - loss: 0.6842 - acc: 0.5801 - val_loss: 0.6873 - val_acc: 0.5695\n",
      "Epoch 117/130\n",
      "1986/1986 [==============================] - 2s 788us/step - loss: 0.6768 - acc: 0.5801 - val_loss: 0.6872 - val_acc: 0.5700\n",
      "Epoch 118/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6737 - acc: 0.5841 - val_loss: 0.6865 - val_acc: 0.5710\n",
      "Epoch 119/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6874 - acc: 0.5846 - val_loss: 0.6867 - val_acc: 0.5710\n",
      "Epoch 120/130\n",
      "1986/1986 [==============================] - 2s 782us/step - loss: 0.7419 - acc: 0.5821 - val_loss: 0.6861 - val_acc: 0.5710\n",
      "Epoch 121/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6827 - acc: 0.5836 - val_loss: 0.6860 - val_acc: 0.5715\n",
      "Epoch 122/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6741 - acc: 0.5836 - val_loss: 0.6858 - val_acc: 0.5720\n",
      "Epoch 123/130\n",
      "1986/1986 [==============================] - 2s 778us/step - loss: 0.6812 - acc: 0.5866 - val_loss: 0.6865 - val_acc: 0.5710\n",
      "Epoch 124/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6755 - acc: 0.5841 - val_loss: 0.6866 - val_acc: 0.5710\n",
      "Epoch 125/130\n",
      "1986/1986 [==============================] - 2s 779us/step - loss: 0.6734 - acc: 0.5841 - val_loss: 0.6864 - val_acc: 0.5705\n",
      "Epoch 126/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6743 - acc: 0.5831 - val_loss: 0.6861 - val_acc: 0.5715\n",
      "Epoch 127/130\n",
      "1986/1986 [==============================] - 2s 775us/step - loss: 0.6727 - acc: 0.5851 - val_loss: 0.6860 - val_acc: 0.5725\n",
      "Epoch 128/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6722 - acc: 0.5856 - val_loss: 0.6859 - val_acc: 0.5725\n",
      "Epoch 129/130\n",
      "1986/1986 [==============================] - 2s 776us/step - loss: 0.6713 - acc: 0.5871 - val_loss: 0.6859 - val_acc: 0.5725\n",
      "Epoch 130/130\n",
      "1986/1986 [==============================] - 2s 785us/step - loss: 0.6795 - acc: 0.5856 - val_loss: 0.6859 - val_acc: 0.5725\n",
      "Training Accuracy: 0.5866\n",
      "Testing Accuracy:  0.5725\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train,Y_train, epochs=130, verbose=1, validation_data=(X_test,Y_test), batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr_acc = []\n",
    "#te_acc = []\n",
    "tr_acc20 = []\n",
    "te_acc20 = []\n",
    "d_lays = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2227 samples, validate on 1486 samples\n",
      "Epoch 1/20\n",
      "2227/2227 [==============================] - 13s 6ms/step - loss: 0.7549 - acc: 0.6057 - val_loss: 0.6707 - val_acc: 0.6265\n",
      "Epoch 2/20\n",
      "2227/2227 [==============================] - 1s 384us/step - loss: 0.6344 - acc: 0.6466 - val_loss: 0.6670 - val_acc: 0.6406\n",
      "Epoch 3/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.6191 - acc: 0.6587 - val_loss: 0.6606 - val_acc: 0.6413\n",
      "Epoch 4/20\n",
      "2227/2227 [==============================] - 1s 389us/step - loss: 0.6124 - acc: 0.6753 - val_loss: 0.6562 - val_acc: 0.6534\n",
      "Epoch 5/20\n",
      "2227/2227 [==============================] - 1s 386us/step - loss: 0.5995 - acc: 0.6879 - val_loss: 0.6556 - val_acc: 0.6541\n",
      "Epoch 6/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.5898 - acc: 0.6960 - val_loss: 0.6626 - val_acc: 0.6588\n",
      "Epoch 7/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.5874 - acc: 0.6996 - val_loss: 0.6738 - val_acc: 0.6581\n",
      "Epoch 8/20\n",
      "2227/2227 [==============================] - 1s 388us/step - loss: 0.5845 - acc: 0.7045 - val_loss: 0.6645 - val_acc: 0.6595\n",
      "Epoch 9/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.5714 - acc: 0.7077 - val_loss: 0.6743 - val_acc: 0.6629\n",
      "Epoch 10/20\n",
      "2227/2227 [==============================] - 1s 388us/step - loss: 0.5635 - acc: 0.7135 - val_loss: 0.6817 - val_acc: 0.6676\n",
      "Epoch 11/20\n",
      "2227/2227 [==============================] - 1s 389us/step - loss: 0.5565 - acc: 0.7185 - val_loss: 0.6741 - val_acc: 0.6696\n",
      "Epoch 12/20\n",
      "2227/2227 [==============================] - 1s 389us/step - loss: 0.5534 - acc: 0.7225 - val_loss: 0.6476 - val_acc: 0.6750\n",
      "Epoch 13/20\n",
      "2227/2227 [==============================] - 1s 390us/step - loss: 0.5492 - acc: 0.7292 - val_loss: 0.6581 - val_acc: 0.6783\n",
      "Epoch 14/20\n",
      "2227/2227 [==============================] - 1s 388us/step - loss: 0.5289 - acc: 0.7589 - val_loss: 0.6750 - val_acc: 0.7234\n",
      "Epoch 15/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.5188 - acc: 0.7831 - val_loss: 0.6660 - val_acc: 0.7322\n",
      "Epoch 16/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.4982 - acc: 0.7943 - val_loss: 0.6945 - val_acc: 0.7591\n",
      "Epoch 17/20\n",
      "2227/2227 [==============================] - 1s 388us/step - loss: 0.4961 - acc: 0.7957 - val_loss: 0.6724 - val_acc: 0.7544\n",
      "Epoch 18/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.4871 - acc: 0.8056 - val_loss: 0.6676 - val_acc: 0.7537\n",
      "Epoch 19/20\n",
      "2227/2227 [==============================] - 1s 388us/step - loss: 0.4771 - acc: 0.8159 - val_loss: 0.7338 - val_acc: 0.7658\n",
      "Epoch 20/20\n",
      "2227/2227 [==============================] - 1s 387us/step - loss: 0.4657 - acc: 0.8231 - val_loss: 0.6974 - val_acc: 0.7631\n",
      "Training Accuracy: 0.8280\n",
      "Testing Accuracy:  0.7631\n",
      "Train on 2227 samples, validate on 1486 samples\n",
      "Epoch 1/20\n",
      "2227/2227 [==============================] - 13s 6ms/step - loss: 0.6834 - acc: 0.6278 - val_loss: 0.6427 - val_acc: 0.6857\n",
      "Epoch 2/20\n",
      "2227/2227 [==============================] - 1s 442us/step - loss: 0.6145 - acc: 0.7032 - val_loss: 0.6249 - val_acc: 0.7153\n",
      "Epoch 3/20\n",
      "2227/2227 [==============================] - 1s 441us/step - loss: 0.5759 - acc: 0.7571 - val_loss: 0.6149 - val_acc: 0.7517\n",
      "Epoch 4/20\n",
      "2227/2227 [==============================] - 1s 441us/step - loss: 0.5536 - acc: 0.7957 - val_loss: 0.6181 - val_acc: 0.7712\n",
      "Epoch 5/20\n",
      "2227/2227 [==============================] - 1s 443us/step - loss: 0.5243 - acc: 0.8150 - val_loss: 0.6135 - val_acc: 0.7759\n",
      "Epoch 6/20\n",
      "2227/2227 [==============================] - 1s 444us/step - loss: 0.5061 - acc: 0.8267 - val_loss: 0.6029 - val_acc: 0.7853\n",
      "Epoch 7/20\n",
      "2227/2227 [==============================] - 1s 444us/step - loss: 0.4862 - acc: 0.8446 - val_loss: 0.6086 - val_acc: 0.7873\n",
      "Epoch 8/20\n",
      "2227/2227 [==============================] - 1s 442us/step - loss: 0.4715 - acc: 0.8500 - val_loss: 0.6237 - val_acc: 0.7934\n",
      "Epoch 9/20\n",
      "2227/2227 [==============================] - 1s 444us/step - loss: 0.4593 - acc: 0.8545 - val_loss: 0.6373 - val_acc: 0.8008\n",
      "Epoch 10/20\n",
      "2227/2227 [==============================] - 1s 444us/step - loss: 0.4466 - acc: 0.8617 - val_loss: 0.6178 - val_acc: 0.7907\n",
      "Epoch 11/20\n",
      "2227/2227 [==============================] - 1s 444us/step - loss: 0.4362 - acc: 0.8702 - val_loss: 0.6348 - val_acc: 0.8015\n",
      "Epoch 12/20\n",
      "2227/2227 [==============================] - 1s 443us/step - loss: 0.4255 - acc: 0.8761 - val_loss: 0.6322 - val_acc: 0.8055\n",
      "Epoch 13/20\n",
      "2227/2227 [==============================] - 1s 441us/step - loss: 0.4179 - acc: 0.8774 - val_loss: 0.6260 - val_acc: 0.8069\n",
      "Epoch 14/20\n",
      "2227/2227 [==============================] - 1s 444us/step - loss: 0.4093 - acc: 0.8810 - val_loss: 0.6212 - val_acc: 0.8048\n",
      "Epoch 15/20\n",
      "2227/2227 [==============================] - 1s 443us/step - loss: 0.4021 - acc: 0.8837 - val_loss: 0.6256 - val_acc: 0.8075\n",
      "Epoch 16/20\n",
      "2227/2227 [==============================] - 1s 443us/step - loss: 0.3951 - acc: 0.8841 - val_loss: 0.6258 - val_acc: 0.8096\n",
      "Epoch 17/20\n",
      "1030/2227 [============>.................] - ETA: 0s - loss: 0.3894 - acc: 0.8932"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-ef532e53f009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adagrad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtr_acc5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_acc5\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for d in d_lays:\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(d, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss=, optimizer='adagrad', metrics=['accuracy'])\n",
    "    history = model.fit(X_train,Y_train, epochs=20, verbose=1, validation_data=(X_test,Y_test), batch_size=10)\n",
    "    loss, accuracy = model.evaluate(X_train, Y_train, verbose=False)\n",
    "    tr_acc5 = tr_acc5 +[accuracy]\n",
    "    print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "    loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)\n",
    "    te_acc5 = te_acc5 +[accuracy]\n",
    "    print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(d_lays[1:],te_acc[1:])\n",
    "plt.plot(d_lays[1:],te_acc5[1:30])\n",
    "plt.plot(d_lays[1:],te_acc5[31:-6])\n",
    "plt.title('Model accuracy on 8 epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('# of Dense Layers')\n",
    "plt.legend(['8 eps', '5 eps','20 eps'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
